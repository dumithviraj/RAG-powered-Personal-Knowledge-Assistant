{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conversational RAG Application With LangChain and OpenAI LLM"
      ],
      "metadata": {
        "id": "TJDBbu95t0nE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qELi9LugtApj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3d7fb3-cf95-4639-9aad-37aba7218b3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.4/438.4 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m376.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.7/96.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Initial the necessary packages\n",
        "!pip install langchain -qU\n",
        "!pip install langchain-openai -qU\n",
        "!pip install langchain-chroma -qU\n",
        "!pip install langchain_community -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "pT8i7bmOt-U7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial OPENAI LLM"
      ],
      "metadata": {
        "id": "ehJMxRoGwyD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial OPENAI LLM"
      ],
      "metadata": {
        "id": "Voci4Lkhwm58"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#SET OPENAI API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# initialized the CahtOpenAI model\n",
        "llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "gn7arNdVwso7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialized Embedding Model"
      ],
      "metadata": {
        "id": "v6wasXsc8KD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ],
      "metadata": {
        "id": "5wuObaTVxxZm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load PDF Document"
      ],
      "metadata": {
        "id": "2VXQjDy79Gsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf -qU"
      ],
      "metadata": {
        "id": "jkV0SH9V9DZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfca83e1-f774-43ea-fa21-830314bf8a5d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/303.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "\n",
        "#Load the PDF Document\n",
        "loader = PyPDFDirectoryLoader(\"/content/Material Synthesis\")\n",
        "\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "5838xLD09QuI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehoLvfUY907L",
        "outputId": "4dbf9289-005d-47ac-ee4e-7910c586d7df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRdutUBR94Im",
        "outputId": "93d8c4d4-da31-49b6-a7d4-13f17bb86615"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-03-21T06:33:37+05:30', 'author': 'Murthi S Kandanapitiye', 'moddate': '2025-03-21T06:33:37+05:30', 'source': '/content/Material Synthesis/Experiment 4- Synthesis of KIO3 and Clock reaction with KIO3.pdf', 'total_pages': 5, 'page': 1, 'page_label': '2'}, page_content='This experiment illustrates the relative ease of oxidation of two halides. A “clock reaction” with \\npotassium iodate is illustrated.  \\nIntroduction \\nIodine can be oxidized to iodate by potassium chlorate . The chlorine in potassium chlorate is \\nreduced to chlorine and the elemental iodine is oxidized to iodate. The examination of the reactants \\nand the products would appear to indicate that iodine has been substituted for chlorine in potassium \\nchlorate. Because iodine, with electrons further from nucleus than chlorine, has a smaller electron \\naffinity than chlorine, the redox reaction becomes energetically favorable. The reaction is found \\nto go best in acid solution, possibly because of the intermediate formation of a little chloric acid.  \\nThe acid solution results in the formation of some KH(IO3)2. For this reason, the solution must be \\nneutralized during the crystallization process in order to obtain pure KIO3.  \\nThe reaction to form potassium iodate generates chlorine . Even though the experiment will only \\ngenerate about 6 mm oles of chlorine, it is not a good practice to vent chlorine into atmosphere. \\nChlorine can be trapped with KOH or with KI solution. Because of the possibility of suck back as \\nthe reaction test tube is sporadically heated, it is not desirable to bubble the evolved gases through \\nthe solution. A solid material which would absorb chlorine by a surface reaction is Ascarite. For \\nmany year Ascarite, which was alkali adsorbed on asbestos, was used to absorb carbon dioxide in \\nthe old microgravimetric analysis of carbon and hydrogen of organic compounds. However, \\nasbestos is now declared to be undesirable and the need for Ascarite has disappeared with the \\nnewer gas chromatographic methods for carbon and hydrogen. A similar scheme might be used \\nwith ceramic fibrous material, such as Fiberfrax, on which KOH might be adsorbed. Such a \\nmaterials would work well as a trapping material, but the preparation of smal l amount of such a \\nsubstance entails some hazards. Pellets of KOH might be used, but the surface area is relatively \\nsmall compared to the volume of KOH. Since the relatively large amounts of KOH in the pellet \\nform will have to be used, disposal of the KOH becomes a consideration. In this experiment, the \\nsmall amounts of chlorine generated is trapped with solid KI which is dispersed by using cotton in \\nthe trapping test tube.  \\nA “clock reaction” is one which shows no observable reaction until a point is reached when a \\nreaction product suddenly becomes visible. Iodate (IO3-) is reduced to iodine (I2) by sulfurous acid \\n(H2SO3) in a sequence of three consecutive reactions. First, iodate is reduced to iod ide. Second, \\niodide, iodate, and hydrogen ion react to form iodine. Third, iodine oxidizes more sulfurous  acid \\nto sulfuric. The first stage is slowest, the last the fastest. Consequently, no iodine appears until the \\nsulfurous acid is all used up.  \\nIf starch is added to the reaction mixture, a dark blue-black starch iodine color will form when the \\niodine appears at the point when all  of the sulfurous acid is used up. Depending on the \\nconcentrations, there will be a time period when nothing seems to be happening. When the \\nsulfurous acid is all used up, the solution will suddenly turn to the dark starch -iodine color. The \\nchange is quite dramatic.')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split Documents into Chunks"
      ],
      "metadata": {
        "id": "byxEIKyJ-BhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Initialize the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
        "\n",
        "# Split the documents into chunks\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "WLieQ9A4974S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rFY8haw-opK",
        "outputId": "0426655e-7f42-4dd0-f226-6da9609443ca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Vector Store and Retriever\n"
      ],
      "metadata": {
        "id": "9KgZuWee-xMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "# Create a vector store from the document chunks\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model)"
      ],
      "metadata": {
        "id": "0iF4k884-sdM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a retriever from the vector store\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "N-568vNj-44Y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Prompt Template\n"
      ],
      "metadata": {
        "id": "ILw4o_Vt_J7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define the system prompt\n",
        "system_prompt = (\n",
        "    \"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "# Create the prompt template\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "5FxmnMEc_HSM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03SekO7H_0K4",
        "outputId": "2c009ed3-e86f-4fc4-bed0-c16ff2602443"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\\n\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Retrieval-Augmented Generation (RAG) Chain\n"
      ],
      "metadata": {
        "id": "WA7UVwtUAEg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "# Create the question-answering chain\n",
        "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Create the RAG chain\n",
        "rag_chain = create_retrieval_chain(retriever, qa_chain)"
      ],
      "metadata": {
        "id": "FV8S8v-8_8Wk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Invoke RAG Chain with Example Questions\n"
      ],
      "metadata": {
        "id": "V-ywX8EdAT1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = rag_chain.invoke({\"input\": \"what are the importances of SDS-PAGE\"})\n",
        "response[\"answer\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "OPBI4fV-AMhN",
        "outputId": "638372ac-7dea-4b9c-a7f2-ac137f1aed60"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SDS-PAGE (Sodium Dodecyl Sulfate Polyacrylamide Gel Electrophoresis) is an important technique in biochemistry and molecular biology for separating proteins based on their molecular weight. Some of the key importances of SDS-PAGE are:\\n\\n1. **Protein Separation**: SDS-PAGE allows for the separation of proteins based on their molecular weight. The proteins are denatured and coated with SDS, which gives them a negative charge and allows for separation solely based on size.\\n\\n2. **Quantification**: It can be used to estimate the molecular weight of unknown proteins by comparing them to known molecular weight markers run on the gel.\\n\\n3. **Purity Analysis**: SDS-PAGE can be used to assess the purity of protein samples by showing the presence of multiple bands (indicating impurities) or a single band (indicating purity).\\n\\n4. **Western Blotting**: SDS-PAGE is often used as the first step in Western blot analysis, where separated proteins are transferred to a membrane for specific protein detection using antibodies.\\n\\n5. **Research and Diagnostic Tool**: It is a valuable tool in research laboratories for studying protein expression, protein-protein interactions, and identifying biomarkers. In clinical settings, SDS-PAGE can be used for diagnostic purposes.\\n\\n6. **Quality Control**: In biotechnology and pharmaceutical industries, SDS-PAGE is used for quality control to ensure the consistency and purity of protein products.\\n\\n7. **Education**: SDS-PAGE is commonly used in educational settings to teach students about protein separation techniques and molecular biology concepts.\\n\\nThese are some of the important aspects of SDS-PAGE and why it is widely used in various fields of science and research.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add Chat History\n"
      ],
      "metadata": {
        "id": "WIQ0oUsQBp85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n",
        "# Define the contextualize system prompt\n",
        "contextualize_system_prompt = (\n",
        "    \"using chat history and the latest user question, just reformulate question if needed and otherwise return it as is\"\n",
        ")\n",
        "\n",
        "# Create the contextualize prompt template\n",
        "contextualize_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the history-aware retriever\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    llm, retriever, contextualize_prompt\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ry33XjNNAfAV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create History-Aware RAG Chain\n"
      ],
      "metadata": {
        "id": "SSxEHc_2B3yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RgKEeIdBvK1",
        "outputId": "9ff62b3d-3f58-4c8e-d239-cdf9ff9ade24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x794bbfbb53a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\\n\\n{context}\"), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the question-answering chain\n",
        "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Create the history aware RAG chain\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, qa_chain)"
      ],
      "metadata": {
        "id": "-g_g53gLB-VZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Manage Chat Session History\n"
      ],
      "metadata": {
        "id": "y6UBaoJ8CbNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "# Initialize the store for session histories\n",
        "store = {}\n",
        "\n",
        "# Function to get the session history for a given session ID\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "# Create the conversational RAG chain with session history\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        ")"
      ],
      "metadata": {
        "id": "5hyEq7m5CWcn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Invoke Conversational RAG Chain with Example Questions\n"
      ],
      "metadata": {
        "id": "f-wEJxcVCwcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "response = conversational_rag_chain.invoke(\n",
        "    {\"input\": \"Can you explain about the synthesise of sodium peroxoborate\"},\n",
        "    config={\"configurable\": {\"session_id\": \"101\"}},\n",
        ")\n",
        "response[\"answer\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "Q8QNzm-wConB",
        "outputId": "20293be3-ef31-4411-c03f-0ddb91b2cd6e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The synthesis of sodium peroxoborate involves the reaction between sodium metaborate (NaBO2), hydrogen peroxide (H2O2), and water (H2O) to form sodium peroxoborate, which has the chemical formula Na2[(OH)2B(O−O)2B(OH)2]⋅6H2O. This reaction is represented by the equation:\\n\\n2NaBO2 + 2H2O2 + 6H2O ⟶ Na2[(OH)2B(O−O)2B(OH)2]⋅6H2O\\n\\nThe experimental procedure for synthesizing sodium peroxoborate involves preparing a solution of sodium metaborate by dissolving borax (Na2B4O7·10H2O) and sodium hydroxide in warm distilled water, then adding hydrogen peroxide. The mixture is cooled in ice, and the reaction takes place to form sodium peroxoborate.\\n\\nIf the crystals of sodium peroxoborate do not appear after 30 minutes, the solution can be seeded with a seed crystal to promote crystallization. The dissociation constant for sodium peroxoborate monohydrate has been measured to be K=0.03 mol/L, indicating significant dissociation of peroxoborate at equilibrium. This suggests that the synthesis process may utilize LeChatelier's principle to shift the equilibrium to the left for better yield.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kV0O5NlQCujB"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}